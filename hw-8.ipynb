{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Натренувати класифікатор на датасеті\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/credit+approval\n",
    "\n",
    "DecisionTreeClassifier\n",
    "\n",
    "Провести всі етапи (підготовка, графічний аналіз, нові фічі....)\n",
    "\n",
    "Додатково: порівняти із LogisticRegression і метричною моделлю\n",
    "\n",
    "\n",
    "* A1:\tb, a.\n",
    "* A2:\tcontinuous.\n",
    "* A3:\tcontinuous.\n",
    "* A4:\tu, y, l, t.\n",
    "* A5:\tg, p, gg.\n",
    "* A6:\tc, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.\n",
    "* A7:\tv, h, bb, j, n, z, dd, ff, o.\n",
    "* A8:\tcontinuous.\n",
    "* A9:\tt, f.\n",
    "* A10:\tt, f.\n",
    "* A11:\tcontinuous.\n",
    "* A12:\tt, f.\n",
    "* A13:\tg, p, s.\n",
    "* A14:\tcontinuous.\n",
    "* A15:\tcontinuous.\n",
    "* A16: +,-         (class attribute) - target"
   ],
   "id": "6c1dd5cf703d4431"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-01T20:24:40.144511Z",
     "start_time": "2024-07-01T20:24:40.141909Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n"
   ],
   "execution_count": 60,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:24:40.180911Z",
     "start_time": "2024-07-01T20:24:40.170579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('hw-8/credit+approval/crx.data')\n",
    "df.columns = ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16']\n",
    "df"
   ],
   "id": "8f76cbb3bded7505",
   "execution_count": 61,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:24:40.200459Z",
     "start_time": "2024-07-01T20:24:40.194815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filter A1 and A2 \n",
    "df[['A1', 'A2']] = df[['A1', 'A2']].replace('?', np.nan)\n",
    "df.dropna(subset=['A1', 'A2'], inplace=True)\n",
    "# Filter A4 \n",
    "df = df[df['A4'].isin(['u', 'y'])].copy()\n",
    "df.dtypes"
   ],
   "id": "a05664824da101dc",
   "execution_count": 62,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:24:40.203837Z",
     "start_time": "2024-07-01T20:24:40.201416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['A2'] = df['A2'].astype(float)\n",
    "print(df.dtypes)"
   ],
   "id": "77c7ee494ee114d2",
   "execution_count": 63,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:24:40.449185Z",
     "start_time": "2024-07-01T20:24:40.204663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "numerical_features = ['A2', 'A3', 'A8', 'A11', 'A15']\n",
    "df[numerical_features].hist(figsize=(10, 6));"
   ],
   "id": "1ce794bfbfb9e03c",
   "execution_count": 64,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:24:40.656866Z",
     "start_time": "2024-07-01T20:24:40.450571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for feature in numerical_features:\n",
    "    plt.figure()  # Creates a new figure\n",
    "    sns.boxplot(x=feature, data=df)\n",
    "    plt.title(f'Boxplot of {feature}')\n",
    "    plt.show()  # Displays the figure"
   ],
   "id": "f8b7026ee5fec6b8",
   "execution_count": 65,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:24:40.801808Z",
     "start_time": "2024-07-01T20:24:40.657607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# looks we need to normalize A15 firstly\n",
    "\n",
    "Q1 = df['A15'].quantile(0.25)\n",
    "Q3 = df['A15'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the upper bound for outliers (we're only interested in the upper side)\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out the upper outliers\n",
    "df_filtered = df[df['A15'] <= upper_bound]\n",
    "\n",
    "print(f\"Original data size: {df.shape}\")\n",
    "print(f\"Filtered data size: {df_filtered.shape}\")\n",
    "\n",
    "# Visualizing the Data Distribution Before and After Removing Outliers\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Before outlier removal\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['A15'], bins=30, edgecolor='black')\n",
    "plt.title('Before Outlier Removal')\n",
    "\n",
    "# After outlier removal\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(df_filtered['A15'], bins=30, edgecolor='black')\n",
    "plt.title('After Outlier Removal')\n"
   ],
   "id": "405391b8dfd32434",
   "execution_count": 66,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:24:40.950146Z",
     "start_time": "2024-07-01T20:24:40.803077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Review how A11 outliers look like. I'd like to remove 5% of outliers only\n",
    "Q1 = df['A11'].quantile(0.05)\n",
    "Q3 = df['A11'].quantile(0.95)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the upper bound for outliers (we're only interested in the upper side)\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out the upper outliers\n",
    "df_filtered = df[df['A11'] <= upper_bound]\n",
    "\n",
    "print(f\"Original data size: {df.shape}\")\n",
    "print(f\"Filtered data size: {df_filtered.shape}\")\n",
    "\n",
    "# Visualizing the Data Distribution Before and After Removing Outliers\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Before outlier removal\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['A11'], bins=30, edgecolor='black')\n",
    "plt.title('Before Outlier Removal')\n",
    "\n",
    "# After outlier removal\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(df_filtered['A11'], bins=30, edgecolor='black')\n",
    "plt.title('After Outlier Removal')"
   ],
   "id": "71b33011b34a3747",
   "execution_count": 67,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:24:41.017898Z",
     "start_time": "2024-07-01T20:24:40.950949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = df_filtered\n",
    "corr_matrix = df[numerical_features].corr()\n",
    "sns.heatmap(corr_matrix)\n",
    "print(corr_matrix)\n",
    "# Correlation looks good - there is no strong correlation between numerical features"
   ],
   "id": "30d1359a6d556e65",
   "execution_count": 68,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:24:43.157834Z",
     "start_time": "2024-07-01T20:24:41.018667Z"
    }
   },
   "cell_type": "code",
   "source": "sns.pairplot(df[numerical_features]);",
   "id": "67e8bc78a48c49f0",
   "execution_count": 69,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:24:43.160337Z",
     "start_time": "2024-07-01T20:24:43.158500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Review and convert categorical features\n",
    "categorical_features = ['A1', 'A4', 'A5', 'A6', 'A7', 'A9', 'A10', 'A12', 'A13', 'A14']"
   ],
   "id": "c1a1bc7a84c9b800",
   "execution_count": 70,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:24:43.166809Z",
     "start_time": "2024-07-01T20:24:43.162110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "category_counts = {}\n",
    "\n",
    "# Loop through each categorical feature and count the unique categories\n",
    "for feature in categorical_features:\n",
    "    unique_count = df[feature].nunique()\n",
    "    category_counts[feature] = unique_count\n",
    "\n",
    "# Convert the dictionary to a DataFrame for better visualization\n",
    "category_counts_df = pd.DataFrame(list(category_counts.items()), columns=['Feature', 'Unique Categories'])\n",
    "category_counts_df"
   ],
   "id": "2599263023e319b6",
   "execution_count": 71,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:24:43.178870Z",
     "start_time": "2024-07-01T20:24:43.167571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Encode categorical features\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_features)\n",
    "df_encoded"
   ],
   "id": "2c6c5ee3b0fb5b84",
   "execution_count": 72,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:36:02.129912Z",
     "start_time": "2024-07-01T20:36:00.217001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn import tree"
   ],
   "id": "2c4346604e6e1aa",
   "execution_count": 74,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:38:15.177781Z",
     "start_time": "2024-07-01T20:38:15.160379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "target = 'A16'\n",
    "X = df_encoded.drop(columns=[target])\n",
    "y = df_encoded[target]\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "# clf.feature_importances_"
   ],
   "id": "f9439ff1c77bdc82",
   "execution_count": 81,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:37:41.515664Z",
     "start_time": "2024-07-01T20:37:40.297066Z"
    }
   },
   "cell_type": "code",
   "source": "tree.plot_tree(clf)",
   "id": "38692582f30e1699",
   "execution_count": 79,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:52:31.842079Z",
     "start_time": "2024-07-01T20:52:28.594342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clf_rf = RandomForestClassifier(max_depth=2, random_state=0).fit(X_train, y_train)\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf, target_names=[f'class_{i}' for i in range(2)]))\n",
    "\n",
    "# As a result it is a little bit better \n",
    "def find_best_model(X_train, y_train):\n",
    "    # Add search best max depth parameter using GridSearchCV\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    param_grid = {\n",
    "        'max_depth': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "    }\n",
    "    clf_rf = RandomForestClassifier(random_state=0)\n",
    "    grid_search = GridSearchCV(estimator=clf_rf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best parameters and the best score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    \n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "    print(f\"Best cross-validation score: {best_score}\")\n",
    "    return best_params\n",
    "\n",
    "best_params = find_best_model(X_train, y_train)\n",
    "\n",
    "clf_rf = RandomForestClassifier(max_depth=best_params['max_depth'], random_state=0).fit(X_train, y_train)\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf, target_names=[f'class_{i}' for i in range(2)]))\n"
   ],
   "id": "95a0049a7dc3ac24",
   "execution_count": 92,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T20:57:52.413648Z",
     "start_time": "2024-07-01T20:57:52.379621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Fix issue with max_iter - looks it was possible only after scaling data\n",
    "pipeline_lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Add a scaler to the pipeline\n",
    "    ('logreg', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "clf_knn = KNeighborsClassifier()\n",
    "\n",
    "# Train the models\n",
    "# clf_lr.fit(X_train, y_train)\n",
    "pipeline_lr.fit(X_train, y_train)\n",
    "clf_knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr = clf_lr.predict(X_test)\n",
    "y_pred_knn = clf_knn.predict(X_test)\n",
    "\n",
    "# Evaluate the models\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "report_lr = classification_report(y_test, y_pred_lr)\n",
    "report_knn = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "conf_matrix_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "# Print the results\n",
    "print(\"Random Forest Classifier\")\n",
    "print(f\"Accuracy: {accuracy_rf}\")\n",
    "print(\"\\nLogistic Regression\")\n",
    "print(f\"Accuracy: {accuracy_lr}\")\n",
    "\n",
    "print(\"\\nK-Nearest Neighbors\")\n",
    "print(f\"Accuracy: {accuracy_knn}\")"
   ],
   "id": "b399b42e03007484",
   "execution_count": 99,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "# As we can see Random Forest hase best results as classifier model. ",
   "id": "b9598c45096903ce",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
