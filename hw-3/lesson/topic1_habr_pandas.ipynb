{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению\n",
    "Авторы материала: программист-исследователь Mail.ru Group, старший преподаватель Факультета Компьютерных Наук ВШЭ Юрий Кашницкий и Data Scientist в Segmento Екатерина Демидова. Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Тема 1. Первичный анализ данных с Pandas</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Pandas](http://pandas.pydata.org)** — это библиотека Python, предоставляющая широкие возможности для анализа данных. С ее помощью очень удобно загружать, обрабатывать и анализировать табличные данные с помощью SQL-подобных запросов. В связке с библиотеками `Matplotlib` и `Seaborn` появляется возможность удобного визуального анализа табличных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные, с которыми работают дата саентисты и аналитики, обычно хранятся в виде табличек — например, в форматах `.csv`, `.tsv` или `.xlsx`. Для того, чтобы считать нужные данные из такого файла, отлично подходит библиотека Pandas.\n",
    "\n",
    "Основными структурами данных в Pandas являются классы `Series` и `DataFrame`. Первый из них представляет собой одномерный индексированный массив данных некоторого фиксированного типа. Второй - это двухмерная структура данных, представляющая собой таблицу, каждый столбец которой содержит данные одного типа. Можно представлять её как словарь объектов типа `Series`. Структура `DataFrame` отлично подходит для представления реальных данных: строки соответствуют признаковым описаниям отдельных объектов, а столбцы соответствуют признакам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "## Демонстрация основных методов Pandas \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создание объекта Series из 5 элементов, индексированных буквами:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "salaries = pd.Series([400, 300, 200, 250], \n",
    "              index = ['Andrew', 'Bob', \n",
    "                       'Charles', 'Ann']) \n",
    "print(salaries)                                                                 "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "salaries[salaries > 250]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Тип данных и переход к numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "# type(salaries)\n",
    "salaries.values"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Индексирование возможно в виде s.Name или s['Name'].**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "print(salaries.Andrew == salaries['Andrew']) "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "salaries['Carl'] = np.nan\n",
    "salaries"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "salaries.fillna(salaries.median(), inplace=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "salaries"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание и изменение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Перейдём к рассмотрению объектов типа DataFrame. Такой объект можно создать из массива numpy, указав названия строк и столбцов.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "df1 = pd.DataFrame(np.random.randn(5, 3), \n",
    "                   index=['o1', 'o2', 'o3', 'o4', 'o5'], \n",
    "                   columns=['f1', 'f2', 'f3'])\n",
    "df1"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Альтернативным способом является создание DataFrame из словаря numpy массивов или списков.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df2 = pd.DataFrame({'A': np.random.random(5), \n",
    "                    'B': ['a', 'b', 'c', 'd', 'e'], \n",
    "                    'C': np.arange(5) > 2})\n",
    "df2"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Тип данных и переход к numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "type(df2)\n",
    "type(df2.values)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обращение к элементам (или целым кускам фрейма):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "df2.at[3, 'B']"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Изменение элементов и добавление новых:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "source": [
    "df2.at[2, 'B'] = 'f'\n",
    "df2"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обработка пропущенных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "df1.at['o2', 'A'] = 2\n",
    "df1.at['o4', 'C'] = np.nan\n",
    "df1"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Булева маска для пропущенных значений (True - там, где был пропуск, иначе - False):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "source": [
    "pd.isnull(df1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dropna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "source": [
    "df1.dropna(how='all', axis=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пропуски можно заменить каким-то значением.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df1.fillna(0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение из файла и первичный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем данные и посмотрим на первые 5 строк с помощью метода `head`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df = pd.read_csv('telecom_churn.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Jupyter-ноутбуках датафреймы `Pandas` выводятся в виде вот таких красивых табличек, и `print(df.head())` выглядит хуже.\n",
    "\n",
    "Кстати, по умолчанию `Pandas` выводит всего 20 столбцов и 60 строк, поэтому если ваш датафрейм больше, воспользуйтесь функцией `set_option`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А также укажем значение параметра `presicion` равным 2, чтобы отображать два знака после запятой (а не 6, как установлено по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "source": [
    "pd.set_option('precision', 2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на размер данных, названия признаков и их типы**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "source": [
    "df.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что в таблице 3333 строки и 20 столбцов. Выведем названия столбцов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "source": [
    "df.columns"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "source": [
    "df.index"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы посмотреть общую информацию по датафрейму и всем признакам, воспользуемся методом **`info`**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "source": [
    "print(df.info())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bool`, `int64`, `float64` и `object` — это типы признаков. Видим, что 1 признак — логический (`bool`), 3 признака имеют тип `object` и 16 признаков — числовые.\n",
    "\n",
    "**Изменить тип колонки** можно с помощью метода `astype`. Применим этот метод к признаку `Churn` и переведём его в `int64`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "source": [
    "df['Churn'] = df['Churn'].astype('int64')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод **`describe`** показывает основные статистические характеристики данных по каждому числовому признаку (типы `int64` и `float64`): число непропущенных значений, среднее, стандартное отклонение, диапазон, медиану, 0.25 и 0.75 квартили."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "source": [
    "df.describe()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы посмотреть статистику по нечисловым признакам, нужно явно указать интересующие нас типы в параметре `include`. Можно также задать `include`='all', чтоб вывести статистику по всем имеющимся признакам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df.describe(include=['object', 'bool'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для категориальных (тип `object`) и булевых (тип `bool`) признаков  можно воспользоваться методом **`value_counts`**. Посмотрим на распределение нашей целевой переменной — `Churn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "source": [
    "df['Total day minutes'].value_counts(dropna=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2850 пользователей из 3333 — лояльные, значение переменной `Churn` у них — `0`.\n",
    "\n",
    "Посмотрим на распределение пользователей по переменной `Area code`. Укажем значение параметра `normalize=True`, чтобы посмотреть не абсолютные частоты, а относительные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "source": [
    "df['Area code'].value_counts(normalize=False)\n",
    "df['Area code'].value_counts(normalize=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сортировка\n",
    "\n",
    "`DataFrame` можно отсортировать по значению какого-нибудь из признаков. В нашем случае, например, по `Total day charge` (`ascending=False` для сортировки по убыванию):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "source": [
    "df.sort_values(by='Total day charge', \n",
    "               ascending=False).head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сортировать можно и по группе столбцов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "source": [
    "df.sort_values(by=['Churn', 'Total day charge'], \n",
    "               ascending=[True, False]).head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Индексация и извлечение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataFrame` можно индексировать по-разному. В связи с этим рассмотрим различные способы индексации и извлечения нужных нам данных из датафрейма на примере простых вопросов.\n",
    "\n",
    "Для извлечения отдельного столбца можно использовать конструкцию вида `DataFrame['Name']`. Воспользуемся этим для ответа на вопрос: **какова доля нелояльных пользователей в нашем датафрейме?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разные способы обращения к столбцам**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "source": [
    "df.Churn.head() # автодополнение\n",
    "df['Churn'].head() # лучше при использовании констант с именами столбцов и можно получить датафрейм df[['Churn']]\n",
    "df[['Churn']]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "source": [
    "df['Churn'].mean()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14,5% — довольно плохой показатель для компании, с таким процентом оттока можно и разориться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень удобной является логическая индексация `DataFrame` по одному столбцу. Выглядит она следующим образом: `df[P(df['Name'])]`, где `P` - это некоторое логическое условие, проверяемое для каждого элемента столбца `Name`. Итогом такой индексации является `DataFrame`, состоящий только из строк, удовлетворяющих условию `P` по столбцу `Name`. \n",
    "\n",
    "Воспользуемся этим для ответа на вопрос: **каковы средние значения числовых признаков среди нелояльных пользователей?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "source": [
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df[(df['Churn'] == 1) & (df['Total day charge'] > 20)]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важно отличать `and` от `&`, а `or` от `|` и не забывать про скобки в условиях**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скомбинировав предыдущие два вида индексации, ответим на вопрос: **сколько в среднем в течение дня разговаривают по телефону нелояльные пользователи**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "source": [
    "df[df['Churn'] == 1]['Total day minutes'].mean()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова максимальная длина международных звонков среди лояльных пользователей (`Churn == 0`), не пользующихся услугой международного роуминга (`'International plan' == 'No'`)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "source": [
    "df[(df['Churn'] == 0) & (df['International plan'] == 'No')]['Total intl minutes'].max()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датафреймы можно индексировать как по названию столбца или строки, так и по порядковому номеру. Для индексации **по названию** используется метод **`loc`**, **по номеру** — **`iloc`**.\n",
    "\n",
    "В первом случае мы говорим _«передай нам значения для id строк от 0 до 5 и для столбцов от State до Area code»_, а во втором — _«передай нам значения первых пяти строк в первых трёх столбцах»_. \n",
    "\n",
    "В случае `iloc` срез работает как обычно, однако в случае `loc` учитываются и начало, и конец среза."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "source": [
    "df1"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "source": [
    "df1.loc['o3':'o5', 'f2':'A']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df.loc[0:5, 'State':'Area code']\n",
    "# df.loc['0':'5', 'State':'Area code'] # то же самое"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df.iloc[0:5, 0:3]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод `ix` индексирует и по названию, и по номеру, но он вызывает путаницу, и поэтому был объявлен устаревшим (deprecated)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Строки и столбцы датафрейма могут быть представлены сериями**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "source": [
    "# df.loc[3, :]\n",
    "# type(df.loc[3, :])\n",
    "# df.loc[:, 'Area code']\n",
    "type(df.loc[:, 'Area code'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если нам нужна первая или последняя строчка датафрейма, пользуемся конструкцией `df[:1]` или `df[-1:]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df[-1:]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применение функций: `apply`, `map` и др."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Применение функции к каждому столбцу:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "source": [
    "df.apply(np.max)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод `apply` можно использовать и для того, чтобы применить функцию к каждой строке. Для этого нужно указать `axis=1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Применение функции к каждой ячейке столбца**\n",
    "\n",
    "Допустим, по какой-то причине нас интересуют все люди из штатов, названия которых начинаются на 'W'. В данному случае это можно сделать по-разному, но наибольшую свободу дает связка `apply`-`lambda` – применение функции ко всем значениям в столбце."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "source": [
    "df[df['State'].apply(lambda state: state[0] == 'W')].head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод `map` можно использовать и для **замены значений в колонке**, передав ему в качестве аргумента словарь вида `{old_value: new_value}`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "source": [
    "d = {'No' : False, 'Yes' : True}\n",
    "df['International plan'] = df['International plan'].map(d)\n",
    "df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичную операцию можно провернуть с помощью метода `replace`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "source": [
    "df = df.replace({'Voice mail plan': d})\n",
    "df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Группировка данных\n",
    "\n",
    "В общем случае группировка данных в Pandas выглядит следующим образом:\n",
    "\n",
    "```\n",
    "df.groupby(by=grouping_columns)[columns_to_show].function()\n",
    "```\n",
    "\n",
    "1. К датафрейму применяется метод **`groupby`**, который разделяет данные по `grouping_columns` – признаку или набору признаков.\n",
    "3. Индексируем по нужным нам столбцам (`columns_to_show`). \n",
    "2. К полученным группам применяется функция или несколько функций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Группирование данных в зависимости от значения признака `Churn` и вывод статистик по трём столбцам в каждой группе.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "source": [
    "columns_to_show = ['Total day minutes', 'Total eve minutes', 'Total night minutes']\n",
    "\n",
    "df.groupby(['Churn'])[columns_to_show].describe(percentiles=[0.5])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем то же самое, но немного по-другому, передав в `agg` список функций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "source": [
    "columns_to_show = ['Total day minutes', 'Total eve minutes', 'Total night minutes']\n",
    "\n",
    "df.groupby(['Churn'])[columns_to_show].agg([np.mean, np.std, np.min, np.max])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объект groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "source": [
    "for i, item in df.groupby(['Churn']):\n",
    "#     print(i)\n",
    "    item\n",
    "item"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сводные таблицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, мы хотим посмотреть, как наблюдения в нашей выборке распределены в контексте двух признаков — `Churn` и `Customer service calls`. Для этого мы можем построить **таблицу сопряженности**, воспользовавшись методом **`crosstab`**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "source": [
    "pd.crosstab(df['Churn'], df['International plan'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "pd.crosstab(df['Churn'], df['Voice mail plan'], normalize=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что большинство пользователей — лояльные и пользуются дополнительными услугами (международного роуминга / голосовой почты)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продвинутые пользователи `Excel` наверняка вспомнят о такой фиче, как **сводные таблицы** (`pivot tables`). В `Pandas` за сводные таблицы отвечает метод **`pivot_table`**, который принимает в качестве параметров:\n",
    "\n",
    "* `values` – список переменных, по которым требуется рассчитать нужные статистики,\n",
    "* `index` – список переменных, по которым нужно сгруппировать данные,\n",
    "* `aggfunc` — то, что нам, собственно, нужно посчитать по группам — сумму, среднее, максимум, минимум или что-то ещё.\n",
    "\n",
    "Давайте посмотрим среднее число дневных, вечерних и ночных звонков для разных `Area code`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "source": [
    "df.pivot_table(['Total day calls', \n",
    "                'Total eve calls', \n",
    "                'Total night calls'], ['Area code'], \n",
    "               aggfunc='mean').head(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразование датафреймов\n",
    "\n",
    "Как и многие другие вещи, добавлять столбцы в `DataFrame` можно несколькими способами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, мы хотим посчитать общее количество звонков для всех пользователей. Создадим объект `total_calls` типа `Series` и вставим его в датафрейм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "source": [
    "total_calls = df['Total day calls'] + df['Total eve calls'] + \\\n",
    "              df['Total night calls'] + df['Total intl calls']\n",
    "df.insert(loc=len(df.columns), column='Total calls', value=total_calls) \n",
    "# loc - номер столбца, после которого нужно вставить данный Series\n",
    "# мы указали len(df.columns), чтобы вставить его в самом конце\n",
    "df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавить столбец из имеющихся можно и проще, не создавая промежуточных `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "source": [
    "df['Total charge'] = df['Total day charge'] + df['Total eve charge'] + \\\n",
    "                     df['Total night charge'] + df['Total intl charge']\n",
    "df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы удалить столбцы или строки, воспользуйтесь методом `drop`, передавая в качестве аргумента нужные индексы и требуемое значение параметра `axis` (`1`, если удаляете столбцы, и ничего или `0`, если удаляете строки):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# избавляемся от созданных только что столбцов\n",
    "# df = df.drop(['Total charge', 'Total calls'], axis=1) \n",
    "\n",
    "# df.drop([1, 2]).head() # а вот так можно удалить строчки\n",
    "# del df['International plan']\n",
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение результата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "source": [
    "df.to_csv('df.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "source": [
    "df.to_html('df.html')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "source": [
    "get_ipython().system('jupyter nbconvert --to script topic1_habr_pandas.ipynb')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "name": "seminar02_part2_pandas.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
